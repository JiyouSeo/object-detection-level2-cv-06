{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Library Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# import cv2\n",
    "\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# import torchvision\n",
    "# from torchvision.models import vgg16\n",
    "# from torchvision.ops import RoIPool\n",
    "# from torchvision.ops import nms\n",
    "# from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# from torchnet.meter import ConfusionMeter, AverageValueMeter\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## Edit freely\n",
    "annotation = '/opt/ml/detection/dataset/train.json' # annotation directory\n",
    "data_dir = '/opt/ml/detection/dataset'    #data image directory\n",
    "check_mode = True    #if true, picked label is printed(0:10)\n",
    "save_dir = '/opt/ml/personel/easy_train_testver.json'\n",
    "thr = 10\n",
    "## --do not edit below--\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def read_json(dir):\n",
    "    with open(dir, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "#레이블 갯수\n",
    "def get_label(dataset, thr = 5):\n",
    "    from collections import defaultdict\n",
    "    from tqdm import tqdm\n",
    "    idxlist = []\n",
    "\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        _, bbox, labels = dataset[i]\n",
    "        bbox, labels = bbox.tolist(), labels.tolist()\n",
    "        if len(labels) <= thr:\n",
    "            idxlist.append(i)\n",
    "\n",
    "    return idxlist\n",
    "\n",
    "\n",
    "def editer(annotation, idxs, save_dir):\n",
    "    train_dataset = read_json(annotation) \n",
    "    \n",
    "    edited_list = []\n",
    "    for ann in train_dataset['annotations']:\n",
    "        if ann['image_id'] in idxs:\n",
    "            edited_list.append(ann)\n",
    "    train_dataset['annotations'] = edited_list\n",
    "\n",
    "    edited_list = []\n",
    "    for ann in train_dataset['images']:\n",
    "        if ann['id'] in idxs:\n",
    "            edited_list.append(ann)\n",
    "    train_dataset['images'] = edited_list\n",
    "    \n",
    "    with open(save_dir, 'w', encoding='utf-8') as make_file:\n",
    "        json.dump(train_dataset, make_file, indent=\"\\t\")\n",
    "    \n",
    "    print(f'done! file_dir: {save_dir}')\n",
    "    return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# TrainDataset\n",
    "class TrainCustom(Dataset):\n",
    "    def __init__(self, annotation, data_dir, transforms = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotation: annotation 파일 위치\n",
    "            data_dir: data가 존재하는 폴더 경로\n",
    "            transforms : transform or not\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # 이미지 아이디 가져오기\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "\n",
    "        # 이미지 정보 가져오기\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "        # 이미지 로드\n",
    "        #image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = None\n",
    "\n",
    "        # 어노테이션 파일 로드\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        # 박스 가져오기\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "\n",
    "        # boxes (x_min, y_min, x_max, y_max)\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "        # 레이블 가져오기\n",
    "        labels = np.array([x['category_id'] for x in anns])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        sample = {\n",
    "            'image': image,\n",
    "            'bboxes': boxes,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        bboxes = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "        boxes = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "\n",
    "        # bboxes (x_min, y_min, x_max, y_max) -> boxes (y_min, x_min, y_max, x_max)\n",
    "        boxes[:, 0] = bboxes[:, 1]\n",
    "        boxes[:, 1] = bboxes[:, 0]\n",
    "        boxes[:, 2] = bboxes[:, 3]\n",
    "        boxes[:, 3] = bboxes[:, 2]\n",
    "\n",
    "\n",
    "        # final boxes: (y_min, x_min, y_max, x_max)\n",
    "        return image, boxes, labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "dataset = TrainCustom(annotation, data_dir, transforms=True)\n",
    "idxs = get_label(dataset, thr)\n",
    "if check_mode:\n",
    "    print(idxs[0:10])\n",
    "else:\n",
    "    print(f'check mode {check_mode}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4883/4883 [00:00<00:00, 9927.14it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4, 6, 7, 8, 9, 10]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "editer(annotation, idxs, save_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done! file_dir: /opt/ml/personel/easy_train_testver.json\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d46d5f9d57d9c71a54d5c977667b5545fd583865b6b06a1b757181255a5d28d0"
  },
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}